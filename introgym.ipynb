{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# Get a list of all available environment IDs\n",
    "env_ids = list(gym.envs.registry.keys())\n",
    "\n",
    "# Print the list of environment IDs\n",
    "print(env_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Reset the environment\n",
    "observation = env.reset()\n",
    "\n",
    "# Loop through a single episode\n",
    "for t in range(200):  # Run for a maximum of 200 steps\n",
    "    # Render the environment\n",
    "    env.render()\n",
    "    \n",
    "    # Sample a random action from the action space\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Take a step in the environment with the sampled action\n",
    "    step_result = env.step(action)\n",
    "    \n",
    "    # Unpack the step result\n",
    "    new_observation, reward, done, info = step_result[:4]\n",
    "    \n",
    "    # If the episode is done (pole has fallen or maximum steps reached), break the loop\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        break\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "#from gym.envs import box2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# Define the environment \n",
    "env = gym.make('BipedalWalker-v3')\n",
    "\n",
    "# Define the number of episodes for training\n",
    "num_episodes = 200\n",
    "\n",
    "# Define the agent (not implemented in this example)\n",
    "class Agent:\n",
    "    def select_action(self, state):\n",
    "        # Placeholder for selecting action\n",
    "        return env.action_space.sample()\n",
    "    \n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        # Placeholder for updating agent\n",
    "        pass\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "# Train the agent using reinforcement learning\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Perform an action\n",
    "        action = agent.select_action(state)\n",
    "\n",
    "        # Apply the action to the environment\n",
    "        step_result = env.step(action)\n",
    "\n",
    "        # Extract next_state, reward, done\n",
    "        next_state, reward, done = step_result[:3]\n",
    "\n",
    "        # Update the total reward\n",
    "        total_reward += reward\n",
    "\n",
    "        # Update the agent based on the reward and next state\n",
    "        agent.update(state, action, reward, next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "env.render()\n",
    "\n",
    "# After training, test the agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.select_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pygame\n",
    "\n",
    "# Set up the BipedalWalker environment\n",
    "env = gym.make('BipedalWalker-v3')\n",
    "\n",
    "# Initialize pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the display\n",
    "screen_width = 600\n",
    "screen_height = 400\n",
    "screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Main loop\n",
    "running = True\n",
    "state = env.reset()  # Initial state\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()\n",
    "    step_result = env.step(action)\n",
    "\n",
    "    # Unpack the step result if it contains four values, otherwise treat it as a tuple\n",
    "    if len(step_result) == 4:\n",
    "        next_state, reward, done, _ = step_result\n",
    "    else:\n",
    "        next_state, reward, done = step_result\n",
    "        _ = None  # Placeholder for the missing info value\n",
    "\n",
    "    # Render the environment\n",
    "    screen.fill((255, 255, 255))  # Clear the screen\n",
    "    x_pos, y_pos = next_state[0], next_state[1]  # Extract position\n",
    "    walker_x = int(screen_width / 2 + x_pos * 50)  # Scale and offset position for rendering\n",
    "    walker_y = int(screen_height / 2 - y_pos * 50)  # Scale and offset position for rendering\n",
    "    pygame.draw.circle(screen, (255, 0, 0), (walker_x, walker_y), 10)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    state = next_state  # Update the state\n",
    "\n",
    "    # Reset the environment if the episode is done\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "\n",
    "    # Cap the frame rate\n",
    "    clock.tick(30)\n",
    "\n",
    "# Close the environment and pygame\n",
    "env.close()\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pygame\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the display\n",
    "screen_width = 800\n",
    "screen_height = 600\n",
    "screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Define the environment\n",
    "env = gym.make('BipedalWalker-v3')\n",
    "\n",
    "# Define the agent (not implemented in this example)\n",
    "class Agent:\n",
    "    def select_action(self, state):\n",
    "        # Placeholder for selecting action\n",
    "        return env.action_space.sample()\n",
    "    \n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        # Placeholder for updating agent\n",
    "        pass\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "# Train the agent using reinforcement learning\n",
    "num_episodes = 200\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Perform an action\n",
    "        action = agent.select_action(state)\n",
    "\n",
    "        # Apply the action to the environment\n",
    "        step_result = env.step(action)\n",
    "        next_state, reward, done, _ = step_result[:4]\n",
    "\n",
    "        # Update the total reward\n",
    "        total_reward += reward\n",
    "\n",
    "        # Update the agent based on the reward and next state\n",
    "        agent.update(state, action, reward, next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        # Render the environment\n",
    "        screen.fill((255, 255, 255))  # Clear the screen\n",
    "\n",
    "        # Render the bipedal walker\n",
    "        walker_pos = next_state[:4]  # Extract walker position\n",
    "        walker_width = 40\n",
    "        walker_height = 80\n",
    "\n",
    "        # Convert walker position to screen coordinates\n",
    "        walker_x = int(screen_width / 2 + walker_pos[0] * 50)\n",
    "        walker_y = int(screen_height / 2 - walker_pos[1] * 50)\n",
    "\n",
    "        # Draw body\n",
    "        pygame.draw.rect(screen, (0, 0, 255), (walker_x, walker_y, walker_width, walker_height))\n",
    "\n",
    "        # Draw legs with knees\n",
    "        leg_width = 10\n",
    "        leg_height = 50\n",
    "        leg_y = walker_y + walker_height\n",
    "\n",
    "        # Left leg with knee\n",
    "        left_knee_x = walker_x + walker_width * 0.3\n",
    "        left_knee_y = leg_y + leg_height * state[4]  # Adjust the left leg's height based on state[4]\n",
    "        left_foot_y = left_knee_y + leg_height * state[5]  # Adjust the left foot's height based on state[5]\n",
    "        pygame.draw.line(screen, (255, 0, 0), (left_knee_x, left_knee_y), (left_knee_x, left_foot_y), leg_width)\n",
    "\n",
    "        # Right leg with knee\n",
    "        right_knee_x = walker_x + walker_width * 0.7\n",
    "        right_knee_y = leg_y + leg_height * state[6]  # Adjust the right leg's height based on state[6]\n",
    "        right_foot_y = right_knee_y + leg_height * state[7]  # Adjust the right foot's height based on state[7]\n",
    "        pygame.draw.line(screen, (255, 0, 0), (right_knee_x, right_knee_y), (right_knee_x, right_foot_y), leg_width)\n",
    "\n",
    "\n",
    "        # Draw head\n",
    "        head_radius = 20\n",
    "        head_x = walker_x + walker_width // 2\n",
    "        head_y = walker_y - head_radius\n",
    "        pygame.draw.circle(screen, (0, 255, 0), (head_x, head_y), head_radius)\n",
    "\n",
    "        # Flip the display\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Cap the frame rate\n",
    "        clock.tick(30)\n",
    "\n",
    "    print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "# After training, test the agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.select_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "# Close the environment and Pygame\n",
    "env.close()\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the display\n",
    "screen_width = 800\n",
    "screen_height = 600\n",
    "screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Define the environment\n",
    "env = gym.make('BipedalWalker-v3')\n",
    "\n",
    "# Define the agent (not implemented in this example)\n",
    "class Agent:\n",
    "    def select_action(self, state):\n",
    "        # Placeholder for selecting action\n",
    "        return env.action_space.sample()\n",
    "    \n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        # Placeholder for updating agent\n",
    "        pass\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "# Train the agent using reinforcement learning\n",
    "num_episodes = 200\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Perform an action\n",
    "        action = agent.select_action(state)\n",
    "\n",
    "        # Apply the action to the environment\n",
    "        step_result = env.step(action)\n",
    "\n",
    "        # Update the total reward\n",
    "        next_state, reward, done, _ = step_result[:4]\n",
    "        total_reward += reward\n",
    "\n",
    "        # Update the agent based on the reward and next state\n",
    "        agent.update(state, action, reward, next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        # Render the environment\n",
    "        screen.fill((255, 255, 255))  # Clear the screen\n",
    "\n",
    "        # Render the bipedal walker\n",
    "        walker_pos = next_state[:4]  # Extract walker position\n",
    "        walker_width = 40\n",
    "        walker_height = 80\n",
    "\n",
    "        # Convert walker position to screen coordinates\n",
    "        walker_x = int(screen_width / 2 + walker_pos[0] * 50)\n",
    "        walker_y = int(screen_height / 2 - walker_pos[1] * 50)\n",
    "\n",
    "        # Draw body\n",
    "        pygame.draw.rect(screen, (0, 0, 255), (walker_x, walker_y, walker_width, walker_height))\n",
    "\n",
    "        # Draw legs\n",
    "        leg_width = 10\n",
    "        leg_height = 50\n",
    "        leg_y = walker_y + walker_height\n",
    "\n",
    "        # Left leg\n",
    "        pygame.draw.rect(screen, (255, 0, 0), (walker_x, leg_y, leg_width, leg_height))\n",
    "        # Right leg\n",
    "        pygame.draw.rect(screen, (255, 0, 0), (walker_x + walker_width - leg_width, leg_y, leg_width, leg_height))\n",
    "\n",
    "        # Flip the display\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Cap the frame rate\n",
    "        clock.tick(30)\n",
    "\n",
    "    print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "# After training, test the agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.select_action(state)\n",
    "    step_result = env.step(action)\n",
    "    state, reward, done, _ = step_result\n",
    "    env.render()\n",
    "\n",
    "# Close the environment and Pygame\n",
    "env.close()\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
